version: "3.9"

services:
  cassandra:
    image: cassandra:4.1
    container_name: cassandra
    environment:
      - CASSANDRA_CLUSTER_NAME=DemoCluster
      - CASSANDRA_NUM_TOKENS=8
      - CASSANDRA_START_RPC=true
    ports:
      - "9042:9042"
    healthcheck:
      test: ["CMD-SHELL", "cqlsh -e 'DESCRIBE CLUSTER' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 10
    volumes:
      - ./data:/var/lib/cassandra
  cassandra-init:
    image: nuvo/docker-cqlsh
    depends_on:
      - cassandra
    environment:
      CQLSH_HOST: cassandra
      CQLSH_PORT: 9042
    volumes:
      - ./schema.cql:/schema.cql
    entrypoint: [ "sh", "-c", "
      echo 'Waiting for Cassandra...';
      until cqlsh $CQLSH_HOST $CQLSH_PORT -e 'DESCRIBE KEYSPACES' >/dev/null 2>&1; do
        sleep 5;
      done;
      echo 'Running schema.cql...';
      cqlsh $CQLSH_HOST $CQLSH_PORT -f /schema.cql;
      echo 'Done.';" ]
    restart: "no"

  spark-master:
    image: spark:latest
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "7077:7077"
      - "8080:8080"
    depends_on:
      - cassandra
    command: ["tail", "-f", "/dev/null"]
  spark-worker:
    image: spark:latest
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    depends_on:
      - spark-master
    command: ["tail", "-f", "/dev/null"]

  jupyter:
    image: jupyter/pyspark-notebook
    container_name: spark-jupyter
    environment:
      - PYSPARK_SUBMIT_ARGS=--master spark://spark-master:7077 pyspark-shell
    ports:
      - "8888:8888"
    depends_on:
      - spark-master
      - cassandra
